{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: \n",
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) artificial neural networks tend to outperform all other algorithms or frameworks.\n",
    "\n",
    "The algorithm differentiates itself in the following ways:\n",
    "\n",
    "- A wide range of applications: Can be used to solve regression, classification, ranking, and user-defined prediction problems.\n",
    "\n",
    "- Portability: Runs smoothly on Windows, Linux, and OS X.\n",
    "\n",
    "- Languages: Supports all major programming languages including C++, Python, R, Java, Scala, and Julia.\n",
    "\n",
    "- Cloud Integration: Supports AWS, Azure, and Yarn clusters and works well with Flink, Spark, and other ecosystems.\n",
    "\n",
    "In this notebook, we will perform the XGBoost algorithm from the xgboost package, plot the confussion matrix and the ROC-AUC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "#### Hugo Cesar Octavio del Sueldo\n",
    "#### Jose Lopez Galdon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date:\n",
    "04/12/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version:\n",
    "1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Numpy & Pandas to work with the DF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "    # Seaborn / matplotlib for graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "    # Impot XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "    # Import Sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import itertools\n",
    "\n",
    "    #Import pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function prints and plots the confusion matrix:\n",
    "\n",
    "cm = confussion_matrix using the prediction values\n",
    "classes = name of the labels\n",
    "cmap & tittle color map and tittle of the plot\n",
    "'''\n",
    "def plot_confusion_matrix(model_predictions, model_name,normalize = False): \n",
    "    cm = confusion_matrix(y_val, model_predictions, labels = [0, 1])\n",
    "    classes=['Fully Pay', 'Non-payment']\n",
    "    cmap = plt.cm.Reds\n",
    "    title = f'{model_name} Confusion Matrix'\n",
    "    fontsize = 12\n",
    "    fontsize_lab = 15\n",
    "    fontsize_tit = 20\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals = 3)\n",
    "        \n",
    "        # Plot params\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize = fontsize_tit)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 0, fontsize = fontsize)\n",
    "    plt.yticks(tick_marks, classes, fontsize = fontsize)\n",
    "    \n",
    "        # Itercool params\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment = 'center',\n",
    "                 color = 'white' if cm[i, j] > thresh else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize = fontsize_lab)\n",
    "    plt.xlabel('Predicted label', fontsize = fontsize_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To automate the work as much as possible, we will parameterize the codes, so in this case, we will create an objetct with\n",
    "    # the path root\n",
    "name = 'X_train'\n",
    "\n",
    "X_train = pd.read_csv(f'../data/03_processed/{name}.csv',  # Path root: here we include an f-string with the variable name\n",
    "                   low_memory = False)                     # To avoid warnings we use set low_memory = False\n",
    "\n",
    "name = 'Y_train'\n",
    "\n",
    "y_train = pd.read_csv(f'../data/03_processed/{name}.csv',  # Path root: here we include an f-string with the variable name\n",
    "                   low_memory = False)                     # To avoid warnings we use set low_memory = False\n",
    "\n",
    "name = 'X_val'\n",
    "\n",
    "X_val = pd.read_csv(f'../data/03_processed/{name}.csv',    # Path root: here we include an f-string with the variable name\n",
    "                   low_memory = False)                     # To avoid warnings we use set low_memory = False\n",
    "\n",
    "name = 'Y_val'\n",
    "\n",
    "y_val = pd.read_csv(f'../data/03_processed/{name}.csv',    # Path root: here we include an f-string with the variable name\n",
    "                   low_memory = False)                     # To avoid warnings we use set low_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Transform to 1d array\n",
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # Train\n",
    "xgboostreg = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    eta=0.1,\n",
    "    max_depth=6,\n",
    "    random_state = 1322,\n",
    "    objective = 'binary:logistic')\n",
    "\n",
    "xgboostreg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict with the test and calculate tha accuracy\n",
    "y_pred = xgboostreg.predict(X_val)\n",
    "\n",
    "print('Accuracy of XGBoost classifier on test set: {:.5f}'.format(xgboostreg.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Set the size\n",
    "plt.figure(figsize = (8, 8))\n",
    "\n",
    "    # Use the function defined above\n",
    "plot_confusion_matrix(y_pred, 'XGBoost Classifier', normalize = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that our XGBoost is quite good predicting Fully Pay members as the other models, because we have more than a 96.5% of *True Positives*, but is not quite good predicting Non-payment clients, this is due from the total customers that non-pay we are predicting well more than 22%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classsification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see at the `classification_report` that our model predict very well Fully Pay customers, because we have a high precision (remember *Precision = TP/(TP + FP)*) and therefore our recall (*Recall = TP/(TP+FN)*) is almost 100% this makes that the f1-score (*F1 Score = 2(Recall Â· Precision) / (Recall + Precision)*) is 88%.\n",
    "\n",
    "On the other hand, as we said above the XGBoost model is very poor predicting Non-payment clientes but better than the other models. The main issue is that the recall is very low, that means we can not detect all the Non-payment, in other words, we have a bigger amount of False Positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create the roc score\n",
    "xgb_roc_auc = roc_auc_score(y_val, xgboostreg.predict(X_val))\n",
    "\n",
    "    # Create the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, xgboostreg.predict_proba(X_val)[:,1])\n",
    "\n",
    "    # Set the figure size\n",
    "plt.figure(figsize = (8, 8))\n",
    "\n",
    "    # Params for the plot\n",
    "plt.plot(fpr, tpr, '#8B0000', label = 'XGBoost (area = %0.5f)' % xgb_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "    # Labels params\n",
    "fontsize = 12\n",
    "fontsize_lab = 15\n",
    "fontsize_tit = 20\n",
    "\n",
    "    # Labels, title and legend modifications\n",
    "plt.xlabel('False Positive Rate', fontsize = fontsize_lab)\n",
    "plt.ylabel('True Positive Rate', fontsize = fontsize_lab)\n",
    "plt.title('Receiver operating characteristic', fontsize = fontsize_tit)\n",
    "plt.legend(loc=\"lower right\", fontsize = fontsize)\n",
    "\n",
    "    # Save the figure for the final reprt\n",
    "plt.savefig('XGBoost_ROC')\n",
    "\n",
    "    # Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s.\n",
    "\n",
    "In this case we have an AUC = 0.59331 this is not very high, but is the best model we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model to disk\n",
    "model = xgboostreg\n",
    "filename = \"xgboost.sav\"\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lending_club",
   "language": "python",
   "name": "lending_club"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
