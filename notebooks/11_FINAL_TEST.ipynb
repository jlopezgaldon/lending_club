{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: \n",
    "# FINAL TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "In this notebook we will perform the process the new data and perform the accuracy with all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "#### Hugo Cesar Octavio del Sueldo\n",
    "#### Jose Lopez Galdon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date:\n",
    "04/12/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version:\n",
    "1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Numpy & Pandas to work with the DF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "    # Pre-processing\n",
    "from sklearn import preprocessing,metrics \n",
    "\n",
    "    # Visualize DF\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "    # Load models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # To automate the work as much as possible, we will parameterize the codes, so in this case, we will create an objetct with\n",
    "    # the path root\n",
    "name = ''\n",
    "\n",
    "data = pd.read_csv(f'../data/01_raw/{name}.csv',           # Path root: here we include an f-string with the variable name\n",
    "                   low_memory = False)                     # To avoid warnings we use set low_memory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Merge Default & Charged Off\n",
    "data['loan_status'] = data['loan_status'].replace({'Default':'Charged Off'})\n",
    "\n",
    "    # We will only select those observations with \"Fully Paid\" & \"Charged Off\"\n",
    "data_binary = data[(data['loan_status'] == \"Fully Paid\") | (data['loan_status'] == \"Charged Off\")]\n",
    "\n",
    "    # Now, we will transform into 0 & 1\n",
    "dummy_dict = {\"Fully Paid\":0, \"Charged Off\":1}\n",
    "\n",
    "    # Finally, we use the dictiony in the dataset\n",
    "data = data_binary.replace({\"loan_status\": dummy_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Select the columns\n",
    "columns = ['loan_status', 'funded_amnt', 'term', 'int_rate', 'emp_length', 'home_ownership', 'annual_inc', 'addr_state', \n",
    "           'inq_last_6mths', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'acc_open_past_24mths', 'avg_cur_bal',\n",
    "           'bc_open_to_buy', 'bc_util', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
    "           'mort_acc', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_tl', 'num_il_tl', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq',\n",
    "           'total_il_high_credit_limit', 'debt_settlement_flag']\n",
    "\n",
    "    # Create a new dataset\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # With a apply and lamba function we, in the same line, convert the variable into a float and we drop the last \n",
    "    # element.\n",
    "data['int_rate'] = data['int_rate'].apply(lambda x: float(x[:-1]))\n",
    "\n",
    "    # Now, we convert the revol_util variable into an string object and the apply the same lamba function as above\n",
    "data['revol_util'] = data['revol_util'].astype('category')\n",
    "data['revol_util'] = data['revol_util'].apply(lambda x: x[:-1])\n",
    "data['revol_util'] = data['revol_util'].astype('float64')\n",
    "\n",
    "    # We create and object we those variable that we want to convert into a categorical named columns_categ\n",
    "columns_categ = [\"emp_length\", \"home_ownership\", \"loan_status\", \"addr_state\", \"term\", \"debt_settlement_flag\"]\n",
    "    \n",
    "    # Below, we transform the variables into categorical with the astype function.\n",
    "data[columns_categ] = data[columns_categ].astype('category')\n",
    "\n",
    "    # with a lambda and apply function we convert the different categories into the variable to a number \n",
    "data[columns_categ] = data[columns_categ].apply(lambda x: x.cat.codes)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include = ['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     # Instance of preprocessing\n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "    # Take numeric columns\n",
    "columns = []\n",
    "\n",
    "    # Apply function\n",
    "data[columns] = scl.fit_transform(data[columns])\n",
    "\n",
    "    # Chech results\n",
    "display(HTML(data.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Y & Data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Set X data\n",
    "X = data.drop(\"loan_status\", axis = 1)\n",
    "\n",
    "    # Set y data\n",
    "y = data[\"loan_status\"]\n",
    "\n",
    "    # Check dimensions\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Select those categorical columns\n",
    "columns_categ = ['term', 'home_ownership', 'emp_length', 'addr_state', 'debt_settlement_flag']\n",
    "    \n",
    "    # Below, we transform the variables into categorical with the astype function.\n",
    "X[columns_categ] = X[columns_categ].astype('category')\n",
    "\n",
    "    # Check the results\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # One Hot Enconding, droping the first column in order to save K-1 \n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    # Check results\n",
    "display(HTML(X.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Parametrize\n",
    "filename = 'logistic_regression'\n",
    "\n",
    "    # Load model\n",
    "model = pickle.load(open(f'../data/04_models/{filename}.sav', 'rb'))\n",
    "\n",
    "    # Print accuracy\n",
    "result = model.score(X, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Parametrize\n",
    "filename = 'random_forest'\n",
    "\n",
    "    # Load model\n",
    "model = pickle.load(open(f'../data/04_models/{filename}.sav', 'rb'))\n",
    "\n",
    "    # Print accuracy\n",
    "result = model.score(X, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Parametrize\n",
    "filename = 'xgboost_tuned'\n",
    "\n",
    "    # Load model\n",
    "model = pickle.load(open(f'../data/04_models/{filename}.sav', 'rb'))\n",
    "\n",
    "    # Print accuracy\n",
    "result = model.score(X, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Parametrize\n",
    "filename = 'svm'\n",
    "\n",
    "    # Load model\n",
    "model = pickle.load(open(f'../data/04_models/{filename}.sav', 'rb'))\n",
    "\n",
    "    # Print accuracy\n",
    "result = model.score(X, y)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lending_club",
   "language": "python",
   "name": "lending_club"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
